[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "l3m-backend"
version = "0.1.0"
description = "A lightweight tool-calling system for local LLMs using llama-cpp-python"
readme = "README.md"
license = {text = "MIT"}
requires-python = ">=3.9"
classifiers = [
    "Development Status :: 3 - Alpha",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
]
keywords = ["llm", "tool-calling", "llama-cpp", "ai", "chatbot"]

dependencies = [
    "pydantic>=2.0",
    "requests>=2.25",
    "numpy>=1.20",
]

[project.optional-dependencies]
llm = [
    "llama-cpp-python>=0.2.0",
]
repl = [
    "prompt_toolkit>=3.0",
]
mcp = [
    "mcp[cli]>=1.0",
]
embeddings = [
    "sentence-transformers>=2.2.0",
]
dev = [
    "pytest>=7.0",
    "pytest-cov>=4.0",
    "pytest-mock>=3.10",
]
all = [
    "l3m-backend[llm,repl,mcp,dev]",
]

[project.scripts]
l3m-init = "l3m_backend.cli.init:main"
l3m-chat = "l3m_backend.cli.chat_repl:main"
l3m-tools = "l3m_backend.cli.tools_cli:main"
l3m-download = "l3m_backend.scripts.download_gguf:main"
l3m-completion = "l3m_backend.cli.completion:main"
l3m-mcp-server = "l3m_backend.cli.mcp_server:main"

[project.urls]
Homepage = "https://github.com/mo/l3m-backend"
Repository = "https://github.com/mo/l3m-backend"

[tool.setuptools.packages.find]
where = ["src"]

[tool.setuptools.package-data]
"*" = ["py.typed"]

[tool.setuptools.data-files]
"share/man/man1" = [
    "docs/man/l3m-chat.1",
    "docs/man/l3m-tools.1",
    "docs/man/l3m-download.1",
    "docs/man/l3m-completion.1",
]
"share/tldr/pages" = [
    "docs/tldr/l3m-init.md",
    "docs/tldr/l3m-chat.md",
    "docs/tldr/l3m-tools.md",
    "docs/tldr/l3m-download.md",
    "docs/tldr/l3m-completion.md",
]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
addopts = "-v"

[tool.coverage.run]
source = ["src/l3m_backend"]
branch = true

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "if TYPE_CHECKING:",
    "if __name__ == .__main__.:",
]
